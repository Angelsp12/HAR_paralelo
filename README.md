![Python](https://img.shields.io/badge/python-3.11-blue)
![scikit-learn](https://img.shields.io/badge/scikit--learn-ML-orange)
![License: MIT](https://img.shields.io/badge/License-MIT-green)
![Status](https://img.shields.io/badge/status-active-success)


# HAR_paralelo

## Reconocimiento de Actividades Humanas con C√≥mputo Paralelo

Este proyecto implementa un sistema de **Reconocimiento de Actividades Humanas (HAR)** utilizando datos del **aceler√≥metro y giroscopio** de tel√©fonos y relojes inteligentes.  
El objetivo principal es **comparar el rendimiento entre una ejecuci√≥n secuencial y una paralela** durante el procesamiento y entrenamiento de modelos de Machine Learning.

## Objetivos
- Analizar datos sensoriales del aceler√≥metro y giroscopio (tel√©fono y reloj).  
- Implementar t√©cnicas de **extracci√≥n de caracter√≠sticas** mediante ventanas de tiempo.  
- Entrenar clasificadores para identificar diferentes actividades humanas.  
- Evaluar el impacto del **c√≥mputo paralelo** en el tiempo de ejecuci√≥n y desempe√±o del modelo.  

---

## Tecnolog√≠as Utilizadas
- **Python 3.x**
- **NumPy, Pandas** ‚Äì manejo y procesamiento de datos.  
- **Scikit-learn** ‚Äì entrenamiento y evaluaci√≥n de modelos.  
- **Joblib / Multiprocessing** ‚Äì paralelizaci√≥n del procesamiento y entrenamiento.  
- **Matplotlib** ‚Äì visualizaci√≥n de resultados.

---

##  Estructura del Repositorio

HAR_paralelo/
‚îÇ
‚îú‚îÄ‚îÄ analisis_accelerometer.ipynb
‚îú‚îÄ‚îÄ analisis_gyroscope.ipynb
‚îú‚îÄ‚îÄ analisis_watch_accelerometer.ipynb
‚îú‚îÄ‚îÄ analisis_watch_gyroscope.ipynb
‚îú‚îÄ‚îÄ entrenamiento_Phones.ipynb
‚îú‚îÄ‚îÄ Entrenamiento_Phones_Gyroscope.ipynb
‚îú‚îÄ‚îÄ Entrenamiento_phones_gyroscopes_secuencial.ipynb
‚îÇ
‚îú‚îÄ‚îÄ entrenamiento.py # Ejemplo de entrenamiento paralelo con Joblib
‚îú‚îÄ‚îÄ requirements.txt # Librer√≠as necesarias
‚îÇ
‚îú‚îÄ‚îÄ  resultados/ 
‚îÇ ‚îú‚îÄ‚îÄ tiempos_entrenamiento.png
‚îÇ ‚îú‚îÄ‚îÄ comparacion_precision.png
‚îÇ ‚îî‚îÄ‚îÄ matriz_confusion.png
‚îÇ
‚îî‚îÄ‚îÄ README.md

## Ejecuci√≥n
###  Configurar entorno
Instala las dependencias ejecutando:
```bash
pip install -r requirements.txt

## Modo Secuencial

Ejecuta el entrenamiento de forma tradicional:

python entrenamiento.py --modo secuencial

## Modo Paralelo

Ejecuta el entrenamiento distribuyendo las tareas entre varios n√∫cleos:

python entrenamiento.py --modo paralelo --n_jobs 4

O ejecuta los notebooks directamente en Jupyter:

Entrenamiento_phones_gyroscopes_secuencial.ipynb

Entrenamiento_Phones_Gyroscope.ipynb


## üìä Evaluaci√≥n del Desempe√±o Computacional

### Tabla 1. Resultados del m√≥dulo de Accelerometer

| N√∫cleos | Tiempo Total (s) | Speedup | Eficiencia (%) |
|:--------:|:----------------:|:--------:|:----------------:|
| 1  | 132.32 | 1.00√ó | 100.00 |
| 2  | 74.56  | 1.77√ó | 88.73 |
| 4  | 44.14  | 3.00√ó | 74.94 |
| 8  | 41.07  | 3.22√ó | 40.27 |
| 12 | 41.50  | 3.19√ó | 26.57 |
| 16 | 43.10  | 3.07√ó | 19.19 |
| 20 | 42.97  | 3.08√ó | 15.40 |

---

### Tabla 2. Resultados del m√≥dulo de Gyroscope

| N√∫cleos | Tiempo Total (s) | Speedup | Eficiencia (%) |
|:--------:|:----------------:|:--------:|:----------------:|
| 1  | 145.46 | 1.00√ó | 100.00 |
| 2  | 80.99  | 1.80√ó | 89.80 |
| 4  | 53.78  | 2.70√ó | 67.62 |
| 8  | 47.94  | 3.03√ó | 37.93 |
| 12 | 46.40  | 3.14√ó | 26.13 |
| 16 | 43.95  | 3.31√ó | 20.69 |
| 20 | 43.72  | 3.33√ó | 16.63 |

---

### Comparaci√≥n General

| Sensor | Speedup M√°ximo | Eficiencia Promedio (1‚Äì8 n√∫cleos) | Reducci√≥n de Tiempo |
|:--------|:----------------:|:---------------------------------:|:--------------------:|
| **Accelerometer** | 3.22√ó (con 8 n√∫cleos) | ~68 % | ‚Üì 69 % (132.3 s ‚Üí 41.0 s) |
| **Gyroscope**      | 3.33√ó (con 20 n√∫cleos) | ~70 % | ‚Üì 70 % (145.5 s ‚Üí 43.7 s) |

üìà **Conclusi√≥n:**  
El rendimiento mejora notablemente al aplicar paralelismo, alcanzando aceleraciones de hasta **3.3√ó** con 8‚Äì20 n√∫cleos.  
La eficiencia comienza a disminuir m√°s all√° de los 8 n√∫cleos, lo que evidencia el impacto del *overhead* de coordinaci√≥n entre procesos.  
En general, el tiempo total de procesamiento se redujo alrededor del **70 %** sin afectar el desempe√±o del modelo.


# Limitaciones

Aunque el uso de c√≥mputo paralelo permiti√≥ reducir significativamente los tiempos de ejecuci√≥n, el sistema presenta algunas limitaciones inherentes al enfoque empleado. En primer lugar, no todo el pipeline de procesamiento es paralelizable; existen etapas que deben ejecutarse de forma secuencial, lo cual limita la aceleraci√≥n total alcanzable. Este comportamiento es consistente con la **Ley de Amdahl**, que establece que la mejora en el rendimiento de un sistema paralelo est√° acotada por la fracci√≥n secuencial del proceso.

Asimismo, al incrementar el n√∫mero de n√∫cleos, la eficiencia disminuye debido al *overhead* asociado a la creaci√≥n, sincronizaci√≥n y comunicaci√≥n entre procesos. Este efecto se vuelve m√°s evidente a partir de cierto n√∫mero de n√∫cleos, donde el costo de coordinaci√≥n supera los beneficios del paralelismo.

Finalmente, la implementaci√≥n actual se basa exclusivamente en paralelismo a nivel de CPU, sin aprovechar aceleradores de hardware como GPUs, lo cual podr√≠a limitar el desempe√±o en escenarios de mayor complejidad.

#Trabajo Futuro

Como trabajo futuro, se propone integrar el entrenamiento real de los modelos directamente en el m√≥dulo de benchmark, sustituyendo las simulaciones actuales por la ejecuci√≥n completa del pipeline de Machine Learning. Adem√°s, ser√≠a relevante evaluar el uso de **aceleraci√≥n por GPU** para comparar su desempe√±o frente al c√≥mputo paralelo en CPU.

Otra l√≠nea de mejora consiste en explorar frameworks de computaci√≥n distribuida como **Apache Spark**, **Dask** o **Ray**, que permitir√≠an escalar el procesamiento a m√∫ltiples nodos y analizar el impacto del paralelismo a nivel de cl√∫ster. Asimismo, se plantea comparar diferentes estrategias de paralelizaci√≥n y modelos de aprendizaje m√°s complejos, como redes neuronales profundas, para evaluar su escalabilidad y eficiencia computacional.


![alt text](image.png) #descripciones de cada Notebook
##Conclusiones

El procesamiento paralelo mejora significativamente la eficiencia del entrenamiento, reduciendo los tiempos de c√≥mputo sin comprometer el rendimiento del modelo.

La carga de trabajo se distribuye de manera efectiva entre n√∫cleos del procesador aprovechando los recursos disponibles.

El enfoque paralelo permite escalar el procesamiento a conjuntos de datos m√°s grandes y modelos m√°s complejos.

Este proyecto demuestra el potencial del c√≥mputo paralelo aplicado al Machine Learning y la Ciencia de Datos.

Autores
√Ångel Miguel S√°nchez P√©rez, Samuel Soriano Chavez, Sergio de Jesus Castillo Molano
Instituto Polit√©cnico Nacional (IPN)
Unidad Profesional Interdisciplinaria de Ingenier√≠a campus Tlaxcala (UPIIT)